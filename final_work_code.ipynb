{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "final_work.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Y0ElTJ9Il3Ov"
      ],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2Ad6IZIsXa7",
        "colab_type": "text"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-09T05:44:25.642500Z",
          "start_time": "2020-09-09T05:44:24.068933Z"
        },
        "id": "LDD5hO2fsXa8",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sklearn\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import preprocessing\n",
        "from hyperopt import hp, tpe, fmin, Trials\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import hyperopt\n",
        "from sklearn.metrics import *\n",
        "import time\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from scipy import interp\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics \n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "import shap  # package used to calculate Shap values\n",
        "import matplotlib.pylab as plt\n",
        "from matplotlib import pyplot\n",
        "from xgboost import plot_importance\n",
        "import csv\n",
        "\n",
        "import scipy\n",
        "from scipy.stats import wilcoxon"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0ElTJ9Il3Ov",
        "colab_type": "text"
      },
      "source": [
        "# Boosting Based Pruning Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-09T06:27:32.260108Z",
          "start_time": "2020-09-09T06:27:32.255062Z"
        },
        "id": "u91tCjlBsXba",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def WeightedError(Ct, X, y, w, N):\n",
        "    \"\"\"\n",
        "    Calculate the training error weighted by sample weights \n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    Ct: a baaging estimator trained on full training data\n",
        "\n",
        "    X : numpy array, shape = [n_samples, n_features]\n",
        "              Training data\n",
        "    y : list or numpy array, shape = [n_samples]\n",
        "              Class labels\n",
        "    \n",
        "    w : numpy array, shape = [n_samples]\n",
        "              boosting like sample weights\n",
        "    N: int\n",
        "        num of samples in training data\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    eu : int\n",
        "        weighted error of Ct on training data\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    y_pred=Ct.predict(X)\n",
        "    eu= np.sum(np.where(y != y_pred, w, 0))/np.sum(w)\n",
        "    return eu\n",
        "\n",
        "def SelectBest(C, X, y, w, N):\n",
        "    \"\"\"\n",
        "    Select the estimator with the mininal training error in pool_c\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    C: pool of baaging estimators trained on full training data\n",
        "\n",
        "    X : numpy array, shape = [n_samples, n_features]\n",
        "              Training data\n",
        "    y : list or numpy array, shape = [n_samples]\n",
        "              Class labels\n",
        "    \n",
        "    w : numpy array, shape = [n_samples]\n",
        "              boosting like sample weights\n",
        "    N: int\n",
        "        num of samples in training data\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    Cmin= estimator with the mininal training error\n",
        "    \n",
        "    min_error : int\n",
        "        weighted error of Ct on training data\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    errors = []\n",
        "    for c in range(len(C)):\n",
        "        errors.append(WeightedError(C[c], X, y, w, N))\n",
        "    min_error= min(errors)\n",
        "    return C[errors.index(min_error)], min_error\n",
        "\n",
        "\n",
        "def reset_weights(n):\n",
        "    \"\"\"\n",
        "    set the sample weights with equal weights\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    n: int\n",
        "        num of samples in training data\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    w: numpy array, shape = [n_samples]\n",
        "        Sample weights\n",
        "    \n",
        "    \"\"\"\n",
        "    return np.ones(shape=n) / n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-09T06:50:47.065262Z",
          "start_time": "2020-09-09T06:50:47.051914Z"
        },
        "id": "Hu_Lqd77sXbc",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BoostingBasedPruning:\n",
        "    \"\"\"\n",
        "    Prune Bagging Ensembles by Boosting.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    T : `int`\n",
        "      number of classifiers.\n",
        "    U : `int`\n",
        "      number of classifiers to select from T [0,100].\n",
        "    weights : `list` (default: `None`)\n",
        "      If `None`, the majority rule voting will be applied to the predicted class labels.\n",
        "        If a list of weights (`float` or `int`) is provided, the averaged raw probabilities (via `predict_proba`)\n",
        "        will be used to determine the most confident class label.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, T, U, weights=None):\n",
        "        self.T = T\n",
        "        self.U = U\n",
        "        self.weights = weights\n",
        "        self.pool_d = []\n",
        "        self.selected= math.ceil(self.T * self.U / 100)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "          build the estimators based on train data.\n",
        "\n",
        "          Parameters\n",
        "          ----------\n",
        "\n",
        "          X : numpy array, shape = [n_samples, n_features]\n",
        "              Training data\n",
        "          y : list or numpy array, shape = [n_samples]\n",
        "              Class labels\n",
        "        \"\"\"\n",
        "        \n",
        "        X = np.float64(X)\n",
        "        y= np.array(y)\n",
        "        pool_c= []\n",
        "\n",
        "        for t in range(self.T):\n",
        "            bg = BaggingClassifier(random_state=(t + 123), n_estimators=1,base_estimator=DecisionTreeClassifier(min_samples_leaf = 15)).fit(X, y)\n",
        "            pool_c.append(bg)\n",
        "        N = len(y)\n",
        "        w = reset_weights(N)\n",
        "        u = 0\n",
        "        \n",
        "        while u < self.selected:\n",
        "            flag = True\n",
        "            Du,eu = SelectBest(pool_c, X, y, w, N)\n",
        "            if (eu > 0.5):\n",
        "                w = reset_weights(N)\n",
        "                #u = u - 1\n",
        "                flag = False\n",
        "            if (flag):\n",
        "                u += 1\n",
        "                self.pool_d.append(Du)\n",
        "                pool_c.remove(Du)\n",
        "            #update weights    \n",
        "            y_pred= Du.predict(X)\n",
        "            w=np.where(y != y_pred, w/(2 * eu), w/(2 * (1 - eu)))    \n",
        "            \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "          Parameters\n",
        "          ----------\n",
        "\n",
        "          X : numpy array, shape = [n_samples, n_features]\n",
        "\n",
        "          Returns\n",
        "          ----------\n",
        "\n",
        "          maj : list or numpy array, shape = [n_samples]\n",
        "              Predicted class labels by majority rule\n",
        "\n",
        "        \"\"\"\n",
        "        \n",
        "        self.classes_ = np.asarray([self.pool_d[m].predict(X) for m in range(self.selected)])\n",
        "\n",
        "        if self.weights:\n",
        "            avg = self.predict_proba(X)\n",
        "\n",
        "            maj = np.apply_along_axis(lambda x: max(enumerate(x), key=operator.itemgetter(1))[0], axis=1, arr=avg)\n",
        "\n",
        "        else:\n",
        "            maj = np.asarray([np.argmax(np.bincount(self.classes_[:, c])) for c in range(self.classes_.shape[1])])\n",
        "\n",
        "        return maj\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "\n",
        "        X : numpy array, shape = [n_samples, n_features]\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "\n",
        "        avg : list or numpy array, shape = [n_samples, n_probabilities]\n",
        "            Weighted average probability for each class per sample.\n",
        "\n",
        "        \"\"\"\n",
        "        self.probas_ = np.asarray([self.pool_d[m].predict_proba(X) for m in range(self.selected)])\n",
        "        avg = np.average(self.probas_, axis=0, weights=self.weights)\n",
        "\n",
        "        return avg\n",
        "        \n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        \"\"\"\n",
        "        Get parameters for this estimator.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        deep : bool, default=True\n",
        "            If True, will return the parameters for this estimator and\n",
        "            contained subobjects that are estimators.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        params : mapping of string to any\n",
        "            Parameter names mapped to their values.\n",
        "        \"\"\"\n",
        "        return {\"T\": self.T, \"U\": self.U}\n",
        "\n",
        "    def set_params(self, **parameters):\n",
        "        \"\"\"\n",
        "        Set the parameters of this estimator.\n",
        "        The method works on simple estimators as well as on nested objects\n",
        "        (such as pipelines). The latter have parameters of the form\n",
        "        ``<component>__<parameter>`` so that it's possible to update each\n",
        "        component of a nested object.\n",
        "        Parameters\n",
        "        ----------\n",
        "        **params : dict\n",
        "            Estimator parameters.\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Estimator instance.\n",
        "        \"\"\"\n",
        "        for parameter, value in parameters.items():\n",
        "          setattr(self, parameter, value)\n",
        "        return self\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYmQ9-VVsXa_",
        "colab_type": "text"
      },
      "source": [
        "# Part C"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-09T05:44:28.362935Z",
          "start_time": "2020-09-09T05:44:28.357667Z"
        },
        "id": "YJJaJTxGsXbA",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "space_xgb = {\n",
        "    'max_depth' : hp.choice('max_depth', range(5, 7, 1)),\n",
        "    'learning_rate' : hp.quniform('learning_rate', 0.01, 0.5, 0.01),\n",
        "    'n_estimators' : hp.choice('n_estimators', range(20, 205, 5)),\n",
        "    'gamma' : hp.quniform('gamma', 0, 0.50, 0.01),\n",
        "    'min_child_weight' : hp.quniform('min_child_weight', 1, 10, 1),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-09T05:44:29.105016Z",
          "start_time": "2020-09-09T05:44:29.102101Z"
        },
        "id": "q87gnHI_sXbF",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "space_bb = {\n",
        "    'T' : hp.choice('T', range(10,150,20)),\n",
        "    'U' : hp.choice('U', range(10,100,20)),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-09T05:44:28.795409Z",
          "start_time": "2020-09-09T05:44:28.790682Z"
        },
        "id": "FgweBkNhsXbC",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def objective_xgb(params):\n",
        "  \"\"\"\n",
        "        objective for Hyperopt tuning of XGBoost (based on sklearn), metric to minimaize\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "\n",
        "        params : dict\n",
        "          tuning parameters\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "\n",
        "        loss : float\n",
        "            1-avarage of 3 folds accuracy\n",
        "\n",
        "      \"\"\"\n",
        "    params = {'max_depth': int(params['max_depth']),\n",
        "              'learning_rate': params['learning_rate'],\n",
        "              'n_estimators': int(params['n_estimators']),\n",
        "              'gamma': params['gamma'],\n",
        "               'min_child_weight': params['min_child_weight'],\n",
        "              'tree_method': 'gpu_hist'\n",
        "                        }\n",
        "    clf = XGBClassifier(**params)\n",
        "    best_score = cross_val_score(clf, X_train, y_train, scoring='accuracy', cv=3, n_jobs=-1).mean()\n",
        "    loss = 1 - best_score\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-09T05:44:29.657717Z",
          "start_time": "2020-09-09T05:44:29.653693Z"
        },
        "id": "qvgh2rx-9dOw",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def objective_bb(params):\n",
        "    \"\"\"\n",
        "        objective for Hyperopt tuning of Boosting Based Pruning, metric to minimaize\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "\n",
        "        params : dict\n",
        "          tuning parameters\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "\n",
        "        loss : float\n",
        "            1-avarage of 3 folds accuracy\n",
        "\n",
        "      \"\"\"\n",
        "\n",
        "\n",
        "    kf=StratifiedKFold(n_splits=3, random_state= 43)\n",
        "    metric=[] # for accuracy\n",
        "    for train_index, test_index in kf.split(X,y):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "        y_train=y_train.tolist()\n",
        "        clf = BoostingBasedPruning(**params)\n",
        "        clf.fit(X_train,y_train)\n",
        "        predictions=clf.predict(X_test)\n",
        "        accuracy_score=metrics.accuracy_score(y_test,predictions) #Return the mean accuracy on the given test data and labels.\n",
        "        metric.append(accuracy_score)\n",
        "    best_score= np.mean(metric)\n",
        "    loss= 1-best_score\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-09T05:44:31.349268Z",
          "start_time": "2020-09-09T05:44:31.345953Z"
        },
        "id": "FMogDhaVsXbT",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hp_tuning(model):\n",
        "    \"\"\"\n",
        "        Bayesian Hyperparameter Tuning with Hyperopt\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "\n",
        "        model : str\n",
        "          model to tuning the parameters\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "\n",
        "        best_params : dict\n",
        "            tuning parameters\n",
        "\n",
        "      \"\"\"\n",
        "\n",
        "    if model== 'XGBClassifier':\n",
        "        objective= objective_xgb\n",
        "        space=space_xgb\n",
        "    else:\n",
        "        objective= objective_bb\n",
        "        space=space_bb\n",
        "    \n",
        "    trials = Trials()\n",
        "    best_result = fmin(\n",
        "    fn=objective,\n",
        "    space=space,\n",
        "    max_evals=50,\n",
        "    rstate=np.random.RandomState(42),\n",
        "    algo=tpe.suggest)\n",
        "    best_barams=hyperopt.space_eval(space,best_result)\n",
        "    return best_barams\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-09T05:44:32.383459Z",
          "start_time": "2020-09-09T05:44:32.380657Z"
        },
        "id": "JAKgjLAjsXbV",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inference(X_test,model):\n",
        "    \"\"\"\n",
        "        calaulate the time of predicting scaled 1000 samples\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "\n",
        "        X_test : numpy array\n",
        "            shape = [n_samples, n_features]\n",
        "\n",
        "        model: object\n",
        "            trained classifier\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "\n",
        "        inference_time : float\n",
        "            time to predict 1000 samples\n",
        "\n",
        "      \"\"\"\n",
        "    if (len(X_test) >= 1000):\n",
        "        X_test=X_test.iloc[1:1000]\n",
        "    n_samples= X_test.shape[0]\n",
        "    start_inference=time.time()\n",
        "    predictions_inference=model.predict(X_test)\n",
        "    stop_inference=time.time()\n",
        "    inference_time=(stop_inference-start_inference)*(1000/n_samples)\n",
        "    return inference_time"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-09T05:44:32.805385Z",
          "start_time": "2020-09-09T05:44:32.801481Z"
        },
        "id": "dy8oYoeysXbX",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def FPR(y_true,y_prediction):\n",
        "    \"\"\"\n",
        "        Evalute the model performance by FPR metirc\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "\n",
        "        y_true : list or numpy array, shape = [n_samples]\n",
        "              Class labels\n",
        "\n",
        "        y_prediction : list or numpy array, shape = [n_samples]\n",
        "              Predicted class labels by model\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "\n",
        "        FPR : float\n",
        "            avarage of false positive rate\n",
        "\n",
        "      \"\"\"\n",
        "    cnf_matrix = confusion_matrix(y_true, y_prediction)\n",
        "\n",
        "    FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \n",
        "    FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
        "    TP = np.diag(cnf_matrix)\n",
        "    TN = cnf_matrix.sum() - (FP + FN + TP)\n",
        "\n",
        "    FP = FP.astype(float)\n",
        "    FN = FN.astype(float)\n",
        "    TP = TP.astype(float)\n",
        "    TN = TN.astype(float)\n",
        "\n",
        "    #false positive rate\n",
        "    FPR = FP.sum()/(FP.sum()+TN.sum()) #micro average\n",
        "    return FPR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-08T19:57:17.913129Z",
          "start_time": "2020-09-08T19:57:17.909824Z"
        },
        "id": "QOp8dx6OsXbh",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(model_name, best_params):\n",
        "\n",
        "    \"\"\"\n",
        "    create classifier model.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    model_name : str\n",
        "        name of classifier model\n",
        "    \n",
        "    best_params : dict\n",
        "      parameters to define the model\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    model : object\n",
        "      insatance of require model\n",
        "    \"\"\"\n",
        "    if model_name== 'XGBClassifier':\n",
        "        deafult = dict(\n",
        "        tree_method='gpu_hist'\n",
        "        )\n",
        "        deafult.update(best_params)\n",
        "        model= XGBClassifier(**deafult)\n",
        "    else:\n",
        "        model=BoostingBasedPruning(**best_param)\n",
        "    return model\n",
        "        "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdLKt_cYoQxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(X,y):\n",
        "  \"\"\"\n",
        "    Handaling missing values, catergorial features.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    X : numpy array, shape = [n_samples, n_features]\n",
        "        Training data\n",
        "    y : list or numpy array, shape = [n_samples]\n",
        "        Class labels\n",
        "  \"\"\"\n",
        "  \n",
        "  #missing values\n",
        "  for column in X.columns:\n",
        "    X[column].fillna(X[column].mode()[0], inplace=True) \n",
        "  #one hot encoder for X\n",
        "  X= pd.get_dummies(X)\n",
        "  #label encoder to target\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  y= pd.Series(le.fit_transform(y),index= y.index)\n",
        "\n",
        "  return X,y\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-09T03:36:55.965145Z",
          "start_time": "2020-09-08T19:57:18.520550Z"
        },
        "id": "s54R_-N9sXbl",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def Part_C(db_path):\n",
        "\n",
        "  #params\n",
        "  average='micro' #avarage metric for multiclass classification\n",
        "  seed = 123\n",
        "\n",
        "  #create dataframe to compare between algorithams\n",
        "  df = pd.DataFrame(columns=['dataset_name','algorithm_name','cross_validation','hyper_parameters_values','accuracy','tpr','fpr','precision','auc','pr_curve','training_time','inference_time'])\n",
        "  kf=StratifiedKFold(n_splits=10, random_state= seed) # for 10fold cross validation\n",
        "\n",
        "\n",
        "  path= db_path\n",
        "  databases_path = os.listdir(path)\n",
        "  alg_list=['XGBClassifier','BoostingBasedPruning']\n",
        "\n",
        "  for database_path in databases_path:\n",
        "      if not database_path in db_list:\n",
        "        for model_name in alg_list:\n",
        "            dataset= pd.read_csv(os.path.join(path, database_path))\n",
        "            dataset_name=database_path \n",
        "            \n",
        "            cross_validation_num=0 # for result table\n",
        "            # split data into X and y\n",
        "            X = dataset.iloc[:,:-1] \n",
        "            y = dataset.iloc[:,-1] #last columns- clss\n",
        "          \n",
        "            X,y= preprocess(X,y)\n",
        "            # split data into train and test sets by cross validation 10 folds\n",
        "            for train_index, test_index in kf.split(X,y):\n",
        "                cross_validation_num=cross_validation_num+1\n",
        "                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "                best_param=hp_tuning(model_name) #tuning the parameters of model\n",
        "                start_training=time.time() #calculate training time\n",
        "                model= get_model(model_name,best_param)\n",
        "                clf = OneVsRestClassifier(model).fit(X_train,y_train) #training by OVR prucedure for multiclass classification\n",
        "                stop_training=time.time()\n",
        "                predictions=clf.predict(X_test) #predict the class\n",
        "                y_score= clf.predict_proba(X_test) #predict the probabilities to class\n",
        "                \n",
        "                #model evaluation \n",
        "                accuracy_score=metrics.accuracy_score(y_test,predictions) \n",
        "                precision=precision_score(y_test,predictions,average=average) \n",
        "                tpr =metrics.recall_score(y_test, predictions, average=average)\n",
        "                fpr=FPR(y_test,predictions)\n",
        "                \n",
        "                classes= y.unique()\n",
        "                y_binary = label_binarize(y_test, classes=range(0,len(y_score[0]),1)) #transform y to binary\n",
        "                if(len(classes)<=2): #for binary classification\n",
        "                    y_score= y_score[:,1]\n",
        "                    y_binary= y_test\n",
        "                auc=roc_auc_score(y_binary, y_score, multi_class=\"ovr\",average=average) \n",
        "                pr_curve=average_precision_score(y_binary, y_score, average=average) \n",
        "                \n",
        "                training_time=stop_training-start_training\n",
        "                inference_time=inference(X_test,clf) #time to predict 1000 samples\n",
        "                df=df.append({\n",
        "                'dataset_name':dataset_name,'algorithm_name':model_name,'cross_validation':cross_validation_num,'hyper_parameters_values':best_param,'accuracy':accuracy_score\n",
        "                    ,'tpr':tpr,'fpr':fpr,'precision':precision,'auc': auc,'pr_curve':pr_curve,'training_time':training_time,'inference_time':inference_time\n",
        "                  },ignore_index=True)\n",
        "            \n",
        "            #save the DataFrame\n",
        "            file_name= str(model_name)+\"_results.csv\"\n",
        "            df.to_csv(file_name,index=False)\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjz9Vy-GmRlY",
        "colab_type": "text"
      },
      "source": [
        "# Part D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HBhFYbXmTia",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f460b146-fb37-494c-dfee-ac8846aab2b1"
      },
      "source": [
        "def Part_D(xgb_data,bb_data):\n",
        "  auc_xgb=xgb_data.groupby(['dataset_name'], as_index= False)['auc'].mean() \n",
        "  auc_bb=bb_data.groupby(['dataset_name'], as_index= False)['auc'].mean()\n",
        "\n",
        "  stat, p =wilcoxon(auc_bb['auc'],auc_xgb['auc'], alternative='two-sided') #regect null hypothesis \n",
        "  print('Statistics=%.0f, p=%.3f' % (stat, p))\n",
        "  stat, p= wilcoxon(auc_xgb['auc'],auc_bb['auc'], alternative='greater')\n",
        "  print('Statistics=%.0f, p=%.3f' % (stat, p))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Statistics=3890, p=0.002\n",
            "Statistics=7136, p=0.001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmva9mFlmVOq",
        "colab_type": "text"
      },
      "source": [
        "# Part E"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9zJWDDUuuS4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prapare_data(xgb_data,bb_data,meta_feature):\n",
        "    \"\"\"\n",
        "    Compare AUC performace between XGBoost and BB and build unified training data\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    xgb_data : numpy array, shape = [10*n_datasets, n_features]\n",
        "        results of XGBoost on datasets with 10 CV\n",
        "    bb_data : numpy array, shape = [10*n_datasets, n_features]\n",
        "        results of BB on datasets with 10 CV\n",
        "\n",
        "    Return\n",
        "    ----------\n",
        "\n",
        "    data : numpy array, shape = [n_datasets, n_meta_features]\n",
        "        Training data for meta learning\n",
        "  \"\"\"\n",
        "  \n",
        "\n",
        "  # calculating avarage auc to dataset\n",
        "  auc_xgb=xgb_data.groupby(['dataset_name'], as_index= False)['auc'].mean() \n",
        "  auc_bb=bb_data.groupby(['dataset_name'], as_index= False)['auc'].mean()\n",
        "\n",
        "  #compare between xgb to bb by auc\n",
        "  comparison= pd.merge(auc_xgb, auc_bb, on='dataset_name')\n",
        "  comparison['target']= np.where(comparison['auc_x'] > comparison['auc_y'],0,1) # '0' for xgb and '1' for bb\n",
        "  #Handling incompatible values\n",
        "  comparison['dataset_name']=comparison['dataset_name'].replace({'abalon.csv': 'abalone.csv','pittsburg-bridges-T-OR-D_R.csv':'pittsburg-bridges-T-OR-D.csv','statlog-heart_.csv':'statlog-heart.csv','wine-quality-red.csv':'wine_quality_red.csv'})\n",
        "  comparison['dataset']= comparison['dataset_name'].apply(lambda x: x.split(\".\")[0]) #remove '.csv'\n",
        "\n",
        "  data= pd.merge(meta_feature,comparison[['target','dataset']], on='dataset', how='outer')\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amg8DVslwp8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_importance(xgb):\n",
        "  \"\"\"\n",
        "    save feature importance by several parameters and plot\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    xgb : Trained meta learning model\n",
        "\n",
        "  \"\"\"\n",
        "  \n",
        "\n",
        "  param = {'weight','gain','cover'}\n",
        "  for char in param:\n",
        "      name=str(char) + '.csv'\n",
        "      ans=xgb.get_booster().get_score(importance_type= char)\n",
        "      with open(name, 'w') as f:  # Just use 'w' mode in 3.x\n",
        "          w = csv.DictWriter(f, ans.keys())\n",
        "          w.writeheader()\n",
        "          w.writerow(ans)\n",
        "\n",
        "  plot_importance(xgb, max_num_features=10) # top 10 most important features\n",
        "  plt.show()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHWixtYkwMNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shap (X_test,xgb):\n",
        "  \"\"\"\n",
        "    Plot shap values and summary\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : numpy array, shape = [n_samples, n_features]\n",
        "        Test data\n",
        "\n",
        "    xgb : Trained meta learning model\n",
        "\n",
        "  \"\"\"\n",
        "  # Create object that can calculate shap values\n",
        "  explainer = shap.TreeExplainer(xgb)\n",
        "  row_to_show = 10\n",
        "  data_for_prediction = X_test.iloc[row_to_show]\n",
        "  # Calculate Shap values\n",
        "  shap_values = explainer.shap_values(data_for_prediction)\n",
        "  shap.initjs()\n",
        "  shap.force_plot(explainer.expected_value, shap_values[0], data_for_prediction)\n",
        "\n",
        "  # Calculate shap_values for all of val_X rather than a single row, to have more data for plot.\n",
        "  shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "  # Make plot. Index of [1] is explained in text below.\n",
        "  shap.summary_plot(shap_values, X_test ,max_display=5)\n",
        "\n",
        "  # make plot\n",
        "  features= ['instances','f120','f123','f124','Features.Mean.StandardDeviation']\n",
        "  for feature in features:\n",
        "      shap.dependence_plot(feature, shap_values, X_test, interaction_index=None)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmCYJv9imWzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def Part_E (xgb_data,bb_data,meta_feature):\n",
        "  \n",
        "  #-------------Init-------------\n",
        "  #define metircs to save\n",
        "  meta_features_output = pd.DataFrame(columns=['dataset_name','algorithm_name','cross_validation','hyper_parameters_values','accuracy','tpr','fpr','precision','auc','pr_curve','training_time','inference_time'])\n",
        "  #for calculate avarage metrics\n",
        "  output=pd.DataFrame(columns=['y_test','predictions','y_score']) \n",
        "  average='micro'\n",
        "\n",
        "  #-------------Get Data-------------\n",
        "  data= prapare_data(xgb_data,bb_data,meta_feature)\n",
        "  y=data['target']\n",
        "  X=data.iloc[:,1:-1]\n",
        "  X, y= preprocess(X,y)\n",
        "  \n",
        "  #-------------Leave One Out#-------------\n",
        "  loo=LeaveOneOut()\n",
        "  loo.get_n_splits(X)\n",
        "  for train_index, test_index in loo.split(X):\n",
        "      X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "      y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "      start_training=time.time()\n",
        "      xgb = XGBClassifier().fit(X_train,y_train)\n",
        "      stop_training=time.time()    \n",
        "      prediction=xgb.predict(X_test)\n",
        "      y_score= xgb.predict_proba(X_test)\n",
        "      training_time=stop_training-start_training\n",
        "      inference_time=inference(X_test,xgb)\n",
        "      output=output.append({'y_test':y_test.to_list(),'predictions':prediction,'y_score':y_score[:,1],'training_time':training_time,'inference_time':inference_time},ignore_index=True)\n",
        "\n",
        "\n",
        "  ##-------------Results-------------\n",
        "  accuracy_score=metrics.accuracy_score(output['y_test'].to_list(),output['predictions'].to_list()) #Return the mean accuracy on the given test data and labels.\n",
        "  precision=precision_score(output['y_test'].to_list(),output['predictions'].to_list(),average=average)\n",
        "  tpr =metrics.recall_score(output['y_test'].to_list(), output['predictions'].to_list(), average=average)\n",
        "  fpr=FPR(output['y_test'].to_list(),output['predictions'].to_list())\n",
        "  auc=roc_auc_score(output['y_test'].to_list(), output['y_score'].to_list(), multi_class=\"ovr\",average=average) \n",
        "  pr_curve=average_precision_score(output['y_test'].to_list(), output['y_score'].to_list(), average=average)  \n",
        "  mean_training_time=output['training_time'].mean()\n",
        "  mean_inference_time=output['inference_time'].mean()\n",
        "  meta_features_output=meta_features_output.append({'accuracy':accuracy_score\n",
        "  ,'tpr':tpr,'fpr':fpr,'precision':precision,'auc': auc,'pr_curve':pr_curve,'training_time':mean_training_time,'inference_time': mean_inference_time\n",
        "  },ignore_index=True)\n",
        "  #save the DataFrame\n",
        "  meta_features_output.to_csv('meta_output.csv',index=False)\n",
        "    \n",
        "  #-------------Shap&Feature Importance------------- \n",
        "  X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1,random_state=123)\n",
        "  xgb =XGBClassifier().fit(X_train,y_train)\n",
        "  shap (X_test,xgb)\n",
        "  feature_importance(xgb)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzaqBHeq0ekm",
        "colab_type": "text"
      },
      "source": [
        "#Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgY07_OH0hBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db_path='./classification_datasets'\n",
        "xgb_path= './all_xgb.csv'\n",
        "bb_path= './bb_all_final.csv'\n",
        "meta_feature_path=  './ClassificationAllMetaFeatures.csv'\n",
        "\n",
        "xgb_data=pd.read_csv(xgb_path) \n",
        "bb_data=pd.read_csv(bb_path) \n",
        "meta_feature= pd.read_csv(meta_feature_path)\n",
        "\n",
        "Part_C(db_path)\n",
        "Part_D(xgb_data,bb_data)\n",
        "Part_E(xgb_data,bb_data,meta_feature)"
      ],
      "execution_count": 5,
      "outputs": []
    }
  ]
}